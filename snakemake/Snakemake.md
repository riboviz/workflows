# Snakemake

https://github.com/snakemake/snakemake

https://snakemake.readthedocs.io/en/stable/

---

## Snakemake

https://slides.com/johanneskoester/snakemake-short#

```
rule mytask:
    input:
        "data/{sample}.txt"
    output:
        "result/{sample}.txt"
    shell:
        "some-tool {input} > {output}"
```

Python, R, CWL scripts:

```
    script:
        "scripts/mytask.py"

    script:
        "scripts/mytask.R"

    cwl:
        "https://github.com/some/cwl-tool"
```

---

## Snakemake tutorial

https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html#tutorial

* GNU Make paradigm.
* Rules define how to create output files from input files.
* Dependencies between rules are determined automatically, via file names.
* Creates a DAG (directed acyclic graph) of jobs that can be automatically parallelized.

* Extension of Python.
* Run transparently on single or multi-core workstations, clusters, batch systems.
* Integrates with Conda package manager Conda and Singularity container.

Setup:

* Use Miniconda 3.

```console
$ mkdir snakemake-tutorial
$ cd snakemake-tutorial
$ wget https://github.com/snakemake/snakemake-tutorial-data/archive/v5.4.5.tar.gz
$ tar -xf v5.4.5.tar.gz --strip 1
$ conda env create --name snakemake-tutorial --file environment.yaml
$ conda info --envs
# conda environments:
#
                         /home/ubuntu/miniconda2
base                  *  /home/ubuntu/miniconda3
snakemake-tutorial       /home/ubuntu/miniconda3/envs/snakemake-tutorial
$ conda activate snakemake-tutorial
$ snakemake --help
```

`environment.yaml`:

```yaml
channels:
  - bioconda
  - conda-forge
dependencies:
  - bwa =0.7.17
  - samtools =1.9
...
```

Basics: An example workflow

Map sequencing reads to a reference genome and call variants on the mapped reads:

* DNA sequencing cuts sample DNA into millions of small pieces, reads.
* To recover the genome of the sample, map these reads against a known reference genome (e.g. the human one from the human genome project) - read mapping.
* Areas of an individual genome can differ from the species-wide consensus represented with the reference genome - variants.
* Responsible for harmless individual differences (e.g. eye color) to diseases (e.g. cancer).
* Investigate differences between all mapped reads and the reference sequence at one position to detect variants.
* Statistically challenging - they have to be distinguished from artifacts generated by the sequencing process.

Step 1: Mapping reads

Create `Snakefile`:

```
# Map reads of a given sample to a given reference genome.
rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/A.fastq"
    output:
        "mapped_reads/A.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"
```

`{...}` defererences rule elements.

If braces are required by the bash command, then double-brace e.g. `ls {{A,B}}.txt`.

Dry run, using `-np`:

* `-n`: `--dry-run`, show execution plan.
* `-p`: print shell commands.

```console
$ snakemake -np mapped_reads/A.bam
Building DAG of jobs...
Job counts:
	count	jobs
	1	bwa_map
	1

[Fri Feb 28 07:34:59 2020]
rule bwa_map:
    input: data/genome.fa, data/samples/A.fastq
    output: mapped_reads/A.bam
    jobid: 0

bwa mem data/genome.fa data/samples/A.fastq | samtools view -Sb - > mapped_reads/A.bam
Job counts:
	count	jobs
	1	bwa_map
	1
This was a dry-run (flag -n). The order of jobs does not reflect the order of execution.
```

A job is an application of rule to generate set of output files.

Run:

```console
$ snakemake mapped_reads/A.bam
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	bwa_map
	1

[Fri Feb 28 07:37:21 2020]
rule bwa_map:
    input: data/genome.fa, data/samples/A.fastq
    output: mapped_reads/A.bam
    jobid: 0

[M::bwa_idx_load_from_disk] read 0 ALT contigs
[M::process] read 25000 sequences (2525000 bp)...
[M::mem_process_seqs] Processed 25000 reads in 0.869 CPU sec, 0.872 real sec
[main] Version: 0.7.17-r1188
[main] CMD: bwa mem data/genome.fa data/samples/A.fastq
[main] Real time: 1.038 sec; CPU: 0.905 sec
[Fri Feb 28 07:37:22 2020]
Finished job 0.
1 of 1 steps (100%) done
Complete log: /home/ubuntu/snakemake-tutorial/.snakemake/log/2020-02-28T073721.891672.snakemake.log
$ ls mapped_reads/
A.bam
```

Snakemake automatically creates missing directories before jobs are executed.

Rerun:

```console
$ snakemake mapped_reads/A.bam
Building DAG of jobs...
Nothing to be done.
Complete log: /home/ubuntu/snakemake-tutorial/.snakemake/log/2020-02-28T073724.208699.snakemake.log
```

Step 2. Generalizing the read mapping rule:

```
rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"
```

`{sample}` is a wildcard.

```console
$ snakemake mapped_reads/B.bam
$ snakemake mapped_reads/C.bam
```

Can have multiple wildcards in file paths.

All output files of a rule have to contain exactly the same wildcards.

```console
$ rm -rf mapped_reads
$ snakemake -np mapped_reads/A.bam mapped_reads/B.bam
$ snakemake -np mapped_reads/{A,B}.bam
```

`{A,B}` is expanded by bash.

Step 3: Sorting read alignments

```
# Sort read alignments
rule samtools_sort:
    input:
        "mapped_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam"
    shell:
        "samtools sort -T sorted_reads/{wildcards.sample} "
        "-O bam {input} > {output}"
```

Best practice to have subsequent steps of a workflow in separate, unique, output folders:

* Keeps the working directory structured.
* Allows Snakemake to prune the search space for dependencies.

`{wildcards.sample}` allows for `sample` wildcard to be used in the shell command. There is one `wildcard` attribute per wildcard.

```console
$ snakemake -np sorted_reads/B.bam
```

Step 4: Indexing read alignments and visualizing the DAG of jobs

```
# Index read alignments.
rule samtools_index:
    input:
        "sorted_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam.bai"
    shell:
        "samtools index {input}"
```

Create DAG image using GraphViz:

```console
$ snakemake --dag sorted_reads/{A,B}.bam.bai | dot -Tsvg > dag.svg
```

Jobs that don't need to be run because their output is up-to-date are dashed.

Wildcards are displayed in job nodes.

Step 5: Calling genomic variants

```
# Aggregate mapped reads from all samples and jointly call genomic variants on them.

SAMPLES = ["A", "B"]

rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam", sample=SAMPLES),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=SAMPLES)
    output:
        "calls/all.vcf"
    shell:
        "samtools mpileup -g -f {input.fa} {input.bam} | "
        "bcftools call -mv - > {output}"
```

`expand("sorted_reads/{sample}.bam", sample=SAMPLES)` searches for files matching pattern where `sample` is in `SAMPLES` e.g. `["sorted_reads/A.bam", "sorted_reads/B.bam"]`.

`expand("sorted_reads/{sample}.{replicate}.bam", sample=SAMPLES, replicate=[0, 1])` would create the product of all elements of SAMPLES and the list [0, 1], yielding `["sorted_reads/A.0.bam", "sorted_reads/A.1.bam", "sorted_reads/B.0.bam", "sorted_reads/B.1.bam"]`.

Our list of samples is defined at the top of the file.

```console
$ snakemake -np calls/all.vcf
$ snakemake  calls/all.vcf
$ rm -rf mapped_reads/ sorted_reads/
$ snakemake --dag calls/all.vcf | dot -Tsvg > dag.svg
```

`fa=` etc. provide names for input, and output, files. These are then dereferenced using `{input.NAME}` or `{output.NAME}`. Using `{input}` and `{output}` will not preserve the order of such named inputs and outputs. Unnamed (positional) input and output files must be defined first.

Long shell commands can be split over multiple lines.

Input and output file lists can contain arbitrary Python statements, so long as they return a string or list of strings.

Step 6: Using custom scripts

Custom Python can be embedded within a script or called-out to.

Create `scripts/plot-quals.py`:

```python
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from pysam import VariantFile

quals = [record.qual for record in VariantFile(snakemake.input[0])]
plt.hist(quals)

plt.savefig(snakemake.output[0])
```

All properties of the calling rule (`input`, `output`, wildcards, etc.) are available as attributes of a global `snakemake` object. For R, there is an analogous S4 `snakemake` object (e.g. the R analogue of the above is `snakemake@input[[1]]` and to access a named input file, `snakemake@input[["myfile"]]`).

```
rule plot_quals:
    input:
        "calls/all.vcf"
    output:
        "plots/quals.svg"
    script:
        "scripts/plot-quals.py"
```

Script paths are relative to the referring Snakefile.

Scripts can instead be invoked via shell commands.

Step 7: Adding a target rule

Can use rule names as targets if a rule has no wildcards.

```
rule all:
    input:
        "plots/quals.svg"
```
```console
$ snakemake -n all
```
```console
$ snakemake -n
```

Snakemake executes first rule in Snakefile if no rule is specified.

```console
$ rm -rf calls/ mapped_reads/ plots/ sorted_reads/
$ snakemake -n all
$ snakemake --dag all | dot -Tsvg > dag.svg
$ snakemake all
```

`--forcerun` can force re-execution of parts of the workflow.

`--reason` displays execution reason:

```console
$ snakemake -n --reason all
...
    input: calls/all.vcf
    output: plots/quals.svg
    jobid: 1
    reason: Missing output files: plots/quals.svg; Input files updated by another job: calls/all.vcf
...
```

Final workflow:

```
SAMPLES = ["A", "B"]

rule all:
    input:
        "plots/quals.svg"

# Map reads of a given sample to a given reference genome.
rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"

# Sort read alignments.
rule samtools_sort:
    input:
        "mapped_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam"
    shell:
        "samtools sort -T sorted_reads/{wildcards.sample} "
        "-O bam {input} > {output}"

# Index read alignments.
rule samtools_index:
    input:
        "sorted_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam.bai"
    shell:
        "samtools index {input}"

# Aggregate mapped reads from all samples and jointly call genomic variants on them.
rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam", sample=SAMPLES),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=SAMPLES)
    output:
        "calls/all.vcf"
    shell:
        "samtools mpileup -g -f {input.fa} {input.bam} | "
        "bcftools call -mv - > {output}"

# Plot quality scores.
rule plot_quals:
    input:
        "calls/all.vcf"
    output:
        "plots/quals.svg"
    script:
        "scripts/plot-quals.py"
```

```console
$ conda deactivate
```

---

## Short tutorial

https://snakemake.readthedocs.io/en/stable/tutorial/short.html

```
conda: "envs/mapping.yaml"
```

Snakemake will create the environment when it is run using `--use-conda`.

```console
$ conda install pygraphviz
$ snakemake --report report.html
```

Create HTML report with workflow image and statistics.
